# -*- coding: utf-8 -*-
"""Practice task 6, Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1g-zJfyawlNOGxt5Dq_YuR7jC3IDWLl9h

## Семинар 6 "Segmentation"

ФИО: __Иванов Иван Иванович__

## Задание

Предлагается поучаствовать в конкурсе https://drive.grand-challenge.org/

Для зачета требуется получить значение dice-coefficient на leaderboard не меньше 0.8 и прислать ноутбук с кодом и кратким отчетом: что пробовали, что сделали, мысли почему окончательная архитектура лучше остальных.

Называйте своего юзера с суффиксом [sphere].

Также первые 3 человека получат бонусные 6, 4, 2 балл соответственно. (deadline: 23:59 14 ноября 2021). Скорее всего будут дополнительные плюшки для призеров конкурса.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

import torch
from torch.utils import data
from torchvision import transforms as tsf
import torch.nn.functional as F
from torch import nn
import scipy.misc

from pathlib import Path

from PIL import Image
import skimage
from skimage import io

import cv2

from google.colab import drive


TRAIN_PATH = './train.pth'
TEST_PATH = './test.pth'
# %matplotlib inline
from IPython.display import clear_output
import random

#!g2.mig
def _epoch(network, loss, loader,
           backward=True,
           optimizer=None,
           device='cpu',
           ravel_init=False):
    losses = []
    for X, y in loader:
        if backward:
            # rotation
            for angle in (0, 15, 30, 45, 60, 75, 90, 180, 270):
                X = tsf.functional.rotate(X, angle)
                y = tsf.functional.rotate(y, angle)
#                 transform = tsf.FiveCrop(80)
                # for crop in range(5):
                #     X = transform(X)[crop]
                #     y = transform(y)[crop]
                for is_flip in range(2):
                    if is_flip:
                        X = tsf.functional.vflip(X)
                        y = tsf.functional.vflip(y)
                    X = X.to(device)
                    y = y.to(device)
                    if ravel_init:
                        X = X.view(X.size(0), -1)
                    network.zero_grad()
                    prediction = network(X)
                    loss_batch = soft_dice_loss(prediction, y)
                    losses.append(loss_batch.cpu().item())
                    loss_batch.backward()
                    optimizer.step()
        else:
            X = X.to(device)
            y = y.to(device)
            network.zero_grad()
            prediction = network(X)
            loss_batch = soft_dice_loss(prediction, y)
            losses.append(loss_batch.cpu().item())
    return losses


def train(network, train_loader, test_loader,
          epochs, learning_rate, ravel_init=False,
          device='cpu', tolerate_keyboard_interrupt=True):
    loss = torch.nn.BCEWithLogitsLoss() 
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0.001)
#     scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.5)
    train_loss_epochs = []
    val_loss_epochs = []
    network = network.to(device)
    try:
        for epoch in range(epochs):
            network.train()
            losses = _epoch(network,
                            loss,
                            train_loader,
                            True,
                            optimizer,
                            device,
                            ravel_init)
            train_loss_epochs.append(np.mean(losses))
            scheduler.step()
            
            network.eval()
            losses = _epoch(network,
                            loss,
                            test_loader,
                            False,
                            optimizer,
                            device,
                            ravel_init)

            val_loss_epochs.append(np.mean(losses))
            clear_output(True)
            print('\rEpoch {0}... (Train/Val) NLL: {1:.3f}/{2:.3f}'.format(
                epoch, train_loss_epochs[-1], val_loss_epochs[-1]))
            
            plt.figure(figsize=(10, 10))
            plt.plot(train_loss_epochs, label='Train')
            plt.plot(val_loss_epochs, label='Val')
            plt.xlabel('Epochs', fontsize=16)
            plt.ylabel('Loss', fontsize=16)
            plt.legend(loc=0, fontsize=16)
            plt.grid()
            plt.show()
    except KeyboardInterrupt:
        if tolerate_keyboard_interrupt:
            pass
        else:
            raise KeyboardInterrupt
    return train_loss_epochs, \
           val_loss_epochs

drive.mount('/content/drive')

def process(dataset_path, mask_path=None):
    data = []
    if mask_path:
        mask_path = Path(mask_path)

    for image in sorted(Path(dataset_path).iterdir()):
        item = {}
        img = cv2.imread(os.fspath(image))
        
        if img.shape[2]>3:
            assert(img[:,:,3]!=255).sum()==0
        
        img = img[:,:,:3]
        item['name'] = image.name.split("_")[0]
        item['img'] = torch.from_numpy(img)
        if mask_path:
            mask = io.imread(mask_path/(item['name'] + "_manual1.gif"))
            item['mask'] = torch.from_numpy(mask)
        data.append(item)
    
    return data
test_data = process('/content/drive/MyDrive/test_grand_challenge/images/')
# torch.save(test_data, TEST_PATH)
train_data = process('/content/drive/MyDrive/training_grand_challenge/images',
                     '/content/drive/MyDrive/training_grand_challenge/1st_manual/')
random.shuffle(train_data)

#!g2.mig
class Dataset():
    def __init__(self, data, source_transform, target_transform=None):
        self.datas = data
        self.s_transform = source_transform
        self.t_transform = target_transform
    def __getitem__(self, index):
        data = self.datas[index]
        img = data['img'].numpy()
        img = self.s_transform(img)
        if self.t_transform:
          mask = data['mask'][:,:,None].byte().numpy()
          mask = self.t_transform(mask)
          return img, mask
        else:
          return img
    def __len__(self):
        return len(self.datas)

s_trans = tsf.Compose([tsf.ToPILImage(),
                       tsf.Resize((256,256)),
                       tsf.ToTensor(),
                       tsf.Normalize(mean = [0.5,0.5,0.5],
                                     std = [0.5,0.5,0.5])
                       ]
                      )

t_trans = tsf.Compose([tsf.ToPILImage(),
                       tsf.Resize((256,256)),
                       tsf.ToTensor()
                       ]
                      )

train_dataset = Dataset(train_data[: int(len(train_data)*0.7)], s_trans, t_trans)
train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=2, batch_size=4)

val_dataset = Dataset(train_data[int(len(train_data)*0.7):], s_trans, t_trans)
val_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1)

test_dataset = Dataset(test_data, s_trans)
test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1)

img, mask = train_dataset[0]
plt.figure(figsize=(12, 12))
plt.subplot(121)
plt.imshow(img.permute(1,2,0).numpy()*0.5+0.5)
plt.subplot(122)
plt.imshow(mask[0].numpy())

# Попробуйте использовать различные функции потерь.
def soft_dice_loss(inputs, targets):
    smoth = 1
    num = targets.size(0)
    m1  = inputs.view(num,-1)
    m2  = targets.view(num,-1)
    intersection = (m1 * m2)
    score = 2. * (intersection.sum(1) + smoth) / (m1.sum(1) + m2.sum(1) + smoth)
    score = 1 - score.sum()/num
    return score

def BCELoss2d(logits, targets):
    probs = F.sigmoid(logits)  # Две проблемы классификации, сигмоидальная эквивалентна softmax
    probs_flat = probs.view(-1)
    targets_flat = targets.view(-1)
    return nn.BCELoss(probs_flat, targets_flat)

class double_conv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(double_conv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        x = self.conv(x)
        return x

class down(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(down, self).__init__()
        self.mpconv = nn.Sequential(
            nn.MaxPool2d(2),
            nn.Dropout(0.3),
            double_conv(in_ch, out_ch)
        )

    def forward(self, x):
        x = self.mpconv(x)
        return x

class up(nn.Module):
    def __init__(self, in_ch, out_ch):
        super(up, self).__init__()
        self.up = nn.Sequential(
            nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2),
            nn.Dropout(0.3)
        )
        self.conv = double_conv(in_ch, out_ch) 

    def forward(self, x1, x2):
        x1 = self.up(x1)
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]

        x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,
                        diffY // 2, diffY - diffY//2))

        x = torch.cat([x2, x1], dim=1)
        x = self.conv(x)
        return x



class UNet(nn.Module):
    def __init__(self, n_channels, n_classes):
        super(UNet, self).__init__()
        self.inc = double_conv(n_channels, 64)
        self.down1 = down(64, 128)
        self.down2 = down(128, 256)
        self.down3 = down(256, 512)
        self.down4 = down(512, 512)
        self.up1 = up(1024, 256)
        self.up2 = up(512, 128)
        self.up3 = up(256, 64)
        self.up4 = up(128, 64)
        self.outc = nn.Conv2d(64, n_classes, 1)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.outc(x)
        x = torch.sigmoid(x)
        return x

model = UNet(3, 1)

A = train(model, train_dataloader, val_dataloader, 600, 0.01, 
          device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.eval()
for ex_id, X in enumerate(test_dataloader):
    X = X.to(device)
    model.zero_grad()
    prediction = model(X)
    
    source_image = cv2.imread("./test/images/%s_test.tif" % str(ex_id + 1).zfill(2))
    tm = prediction[0][0].cpu().detach().numpy()
    tm = skimage.transform.resize(tm, source_image.shape[:-1])
    tm = (tm > 0.5).astype(int) * 255
    
    Is = cv2.imwrite(f"./result/{(ex_id + 1)}.png", tm)
    print(Is)